{
  "moduleId": "08-deployment",
  "exerciseId": "pre-launch-checklist",
  "title": "Pre-Launch Checklist",
  "estimatedTime": "30 minutes",
  "overview": "Complete the pre-launch checklist for your capstone agent. This is the final verification before going live - ensuring you haven't missed anything critical.",
  "objectives": [
    "Verify all deployment requirements are met",
    "Confirm testing coverage is adequate",
    "Validate security and operational readiness",
    "Prepare rollback and incident response plans"
  ],
  "context": "Deploying to production is exciting, but rushing leads to incidents. This checklist ensures you've done the work to deploy with confidence. Every 'yes' should have evidence. Every 'no' needs a plan.",
  "instructions": "Go through each section of the checklist. For each item, indicate whether it's complete and provide evidence or notes. Be honest - it's better to identify gaps now than in production.\n\n**Deployment philosophy:** If it's not tested, it doesn't work. If it's not monitored, you don't know when it breaks.",
  "deliverable": {
    "type": "form",
    "fields": [
      {
        "name": "agent_name",
        "label": "Agent Name",
        "type": "text",
        "required": true
      },
      {
        "name": "target_launch_date",
        "label": "Target Launch Date",
        "type": "text",
        "placeholder": "e.g., 2026-01-15",
        "required": true
      },
      {
        "name": "code_checklist",
        "label": "Code Quality",
        "type": "checklist",
        "options": [
          {"value": "no_secrets", "label": "No secrets/credentials in code"},
          {"value": "env_config", "label": "Configuration via environment variables"},
          {"value": "error_handling", "label": "All error paths handled gracefully"},
          {"value": "input_validation", "label": "User input validated and sanitized"},
          {"value": "logging", "label": "Structured logging implemented"},
          {"value": "code_reviewed", "label": "Code reviewed by another person"}
        ],
        "required": true
      },
      {
        "name": "testing_checklist",
        "label": "Testing Coverage",
        "type": "checklist",
        "options": [
          {"value": "unit_tests", "label": "Unit tests for all tools (passing)"},
          {"value": "integration_tests", "label": "Integration tests for agent-tool interaction"},
          {"value": "e2e_tests", "label": "End-to-end conversation tests"},
          {"value": "edge_cases", "label": "Edge cases tested (empty input, long input, special chars)"},
          {"value": "load_test", "label": "Basic load testing completed"},
          {"value": "manual_testing", "label": "Manual testing by someone other than developer"}
        ],
        "required": true
      },
      {
        "name": "security_checklist",
        "label": "Security",
        "type": "checklist",
        "options": [
          {"value": "iam_least_privilege", "label": "IAM policy follows least privilege"},
          {"value": "secrets_secured", "label": "Secrets stored in Secrets Manager (not env vars)"},
          {"value": "rate_limiting", "label": "Rate limiting configured"},
          {"value": "input_filtering", "label": "Prompt injection mitigations in place"},
          {"value": "pii_handling", "label": "PII handling documented and compliant"},
          {"value": "audit_logging", "label": "Audit logging for sensitive operations"}
        ],
        "required": true
      },
      {
        "name": "operations_checklist",
        "label": "Operations",
        "type": "checklist",
        "options": [
          {"value": "monitoring_setup", "label": "CloudWatch dashboard created"},
          {"value": "alerts_configured", "label": "Critical and warning alerts configured"},
          {"value": "on_call_defined", "label": "On-call rotation or owner defined"},
          {"value": "runbook_written", "label": "Debugging runbook documented"},
          {"value": "cost_alerts", "label": "Cost alerts configured"},
          {"value": "backup_strategy", "label": "Data backup strategy defined (if applicable)"}
        ],
        "required": true
      },
      {
        "name": "deployment_checklist",
        "label": "Deployment",
        "type": "checklist",
        "options": [
          {"value": "staging_tested", "label": "Tested in staging environment"},
          {"value": "rollback_plan", "label": "Rollback procedure documented and tested"},
          {"value": "feature_flags", "label": "Feature flags for gradual rollout (if needed)"},
          {"value": "dependency_versions", "label": "All dependencies pinned to specific versions"},
          {"value": "infra_as_code", "label": "Infrastructure defined as code (CDK/Terraform)"},
          {"value": "ci_cd_pipeline", "label": "CI/CD pipeline configured"}
        ],
        "required": true
      },
      {
        "name": "incomplete_items",
        "label": "Items Not Complete - Plans",
        "type": "textarea",
        "placeholder": "For any items you couldn't check above, explain why and what your plan is to address them before launch.",
        "required": false,
        "helpText": "It's OK to have gaps, but you need a plan"
      },
      {
        "name": "rollback_plan",
        "label": "Rollback Plan",
        "type": "textarea",
        "placeholder": "If something goes wrong after launch, how do you roll back? Be specific: what commands, what order, how long?",
        "required": true,
        "minLength": 100
      },
      {
        "name": "success_criteria",
        "label": "Launch Success Criteria",
        "type": "textarea",
        "placeholder": "How will you know the launch was successful? What metrics will you watch in the first hour? First day?",
        "required": true,
        "minLength": 50
      },
      {
        "name": "stakeholder_communication",
        "label": "Stakeholder Communication",
        "type": "textarea",
        "placeholder": "Who needs to know about this launch? How will you communicate status?",
        "required": true
      },
      {
        "name": "post_launch_plan",
        "label": "Post-Launch Plan",
        "type": "textarea",
        "placeholder": "What will you do in the first week after launch? Monitoring cadence? Feedback collection?",
        "required": true
      }
    ]
  },
  "successCriteria": [
    "At least 80% of checklist items are marked complete",
    "Any incomplete items have documented plans",
    "Rollback plan is specific and actionable",
    "Success criteria are measurable",
    "Post-launch plan shows ongoing ownership"
  ],
  "exampleSubmission": {
    "agent_name": "SupportBot",
    "target_launch_date": "2026-01-15",
    "code_checklist": ["no_secrets", "env_config", "error_handling", "input_validation", "logging", "code_reviewed"],
    "testing_checklist": ["unit_tests", "integration_tests", "e2e_tests", "edge_cases", "manual_testing"],
    "security_checklist": ["iam_least_privilege", "secrets_secured", "rate_limiting", "input_filtering", "pii_handling", "audit_logging"],
    "operations_checklist": ["monitoring_setup", "alerts_configured", "runbook_written", "cost_alerts"],
    "deployment_checklist": ["staging_tested", "rollback_plan", "dependency_versions", "infra_as_code"],
    "incomplete_items": "**Load testing (testing):** Haven't done formal load testing yet. Plan: Will run basic load test (100 concurrent users for 10 min) before launch using k6. Target: p99 latency under 10s.\n\n**On-call defined (operations):** Just me for now - single point of failure. Plan: Set up PagerDuty, I'll be on-call for first 2 weeks, then work on getting backup coverage.\n\n**Feature flags (deployment):** Not implemented. Plan: Low risk for MVP - we're starting with internal users only. Will add feature flags before public launch.\n\n**CI/CD pipeline (deployment):** Currently deploying manually via scripts. Plan: Set up GitHub Actions pipeline after successful launch. Risk is low for now since only I deploy.",
    "rollback_plan": "**Rollback procedure (target: under 10 minutes):**\n\n1. **Immediate:** Point DNS/API Gateway to 'maintenance mode' Lambda that returns friendly error (30 sec)\n   ```bash\n   aws apigatewayv2 update-stage --api-id xxx --stage-name prod --route-settings '{\"POST /chat\": {\"ThrottlingBurstLimit\": 0}}'\n   ```\n\n2. **Revert Lambda:** Deploy previous version (2 min)\n   ```bash\n   aws lambda update-alias --function-name supportbot --name prod --function-version <previous>\n   ```\n\n3. **Verify:** Test with curl, check CloudWatch for errors (2 min)\n\n4. **Restore traffic:** Re-enable API Gateway (30 sec)\n\n5. **Communicate:** Update #supportbot-status Slack channel\n\n**Previous version always kept:** Lambda versions are immutable, I keep last 3 versions.\n\n**Database rollback:** N/A - agent is stateless, no database migrations to roll back.",
    "success_criteria": "**First hour:**\n- Zero 5xx errors\n- p99 latency under 10 seconds\n- At least 1 successful conversation (proves it works)\n\n**First day:**\n- Error rate under 1%\n- At least 10 conversations completed\n- No critical alerts fired\n- Positive feedback from at least 2 internal testers\n\n**First week:**\n- Resolution rate above 60% (conversations resolved without escalation)\n- No security incidents\n- Cost within 150% of estimate ($50/day)\n- Internal users report agent is 'helpful' not 'frustrating'",
    "stakeholder_communication": "**Pre-launch:**\n- Email to customer support team explaining what SupportBot is, what it can/can't do\n- Slack message in #product-updates with launch timeline\n\n**Launch day:**\n- Post in #supportbot-status: 'SupportBot is live for internal testing'\n- Direct message to 5 volunteer testers asking them to try it\n\n**Daily for first week:**\n- EOD summary in #supportbot-status: conversations, resolution rate, any issues\n\n**Escalation path:**\n- Issues: Post in #supportbot-status and page me\n- Critical (data leak, security): Immediately page me + notify security team",
    "post_launch_plan": "**Day 1-3: Intensive monitoring**\n- Check CloudWatch dashboard every 2 hours\n- Review every escalated conversation\n- Fix any blocking bugs same-day\n\n**Day 4-7: Stabilization**\n- Daily dashboard review (morning)\n- Weekly summary of metrics to stakeholders\n- Start collecting improvement ideas\n\n**Week 2: Iteration**\n- Analyze most common questions that fail\n- Add 10 more FAQs based on gaps\n- Improve tool descriptions if wrong tools being selected\n\n**Week 3-4: Expand**\n- If stable, expand to more internal users\n- Plan for public launch\n- Set up CI/CD pipeline\n\n**Ongoing:**\n- Monthly review of resolution rate, cost, user feedback\n- Quarterly: evaluate if specialist agent (multi-agent) is needed"
  },
  "tutorPrompt": "The student has completed their pre-launch checklist. Review for: (1) Are critical items (security, rollback, monitoring) complete?, (2) Do incomplete items have realistic plans?, (3) Is the rollback plan actually actionable?, (4) Are success criteria measurable and realistic?, (5) Does the post-launch plan show ongoing ownership? This is the final exercise before deployment - make sure they're ready!"
}
